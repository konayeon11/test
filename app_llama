# -*- coding: utf-8 -*-
# app_gpt.py

import streamlit as st
import pandas as pd
import lightgbm as lgb
import json
import requests
from openai import OpenAI

# ==============================
# ğŸ”‘ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
# ==============================
OPENAI_API_KEY = st.secrets.get("openai", {}).get("api_key")
HF_API_KEY = st.secrets.get("huggingface", {}).get("api_key")
HF_MODEL = st.secrets.get("huggingface", {}).get("model", "nvidia/Llama-3.3-Nemotron-Super-49B-v1.5")
HF_API_URL = st.secrets.get("huggingface", {}).get(
    "api_url", f"https://api-inference.huggingface.co/models/{HF_MODEL}"
)

# âœ… ë°±ì—”ë“œ ìë™ ì„ íƒ
BACKEND = "hf" if HF_API_KEY else ("openai" if OPENAI_API_KEY else None)
if BACKEND is None:
    st.error("âŒ ì‚¬ìš©í•  API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. secrets.tomlì— [huggingface.api_key] ë˜ëŠ” [openai.api_key]ë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”.")
    st.stop()

st.caption(f"âš™ï¸ í˜„ì¬ ë°±ì—”ë“œ: {BACKEND.upper()}")

# ==============================
# ğŸ§  ë§ì¶¤í˜• ì¡°ì–¸ ìƒì„± í•¨ìˆ˜
# ==============================
def generate_lifestyle_advice(risk_factors: dict) -> str:
    risk_factors_str = json.dumps(risk_factors, ensure_ascii=False)

    prompt = f"""
# ì—­í•  (Role)
ë‹¹ì‹ ì€ ì‹¬í˜ˆê´€ì§ˆí™˜ ì˜ˆë°©ê³¼ ê´€ë¦¬ë¥¼ ì „ë¬¸ìœ¼ë¡œ í•˜ëŠ” ì˜ë£Œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ìµœì‹  ì—°êµ¬ì™€ ì„ìƒ ì§€ì¹¨ì— ê¸°ë°˜í•˜ì—¬ ì¼ë°˜ì¸ì˜ ê±´ê°• í–‰ë™ì„ íš¨ê³¼ì ìœ¼ë¡œ ë³€í™”ì‹œí‚¬ ìˆ˜ ìˆë„ë¡ ë•ëŠ” ì—­í• ì„ ë§¡ê³  ìˆìŠµë‹ˆë‹¤.

# ëŒ€ìƒ (Audience)
ë‹¹ì‹ ì˜ ì¡°ì–¸ì„ ë°›ì„ ëŒ€ìƒì€ ê±´ê°•ì— ê´€ì‹¬ì´ ë†’ì§€ë§Œ ì˜ë£Œ ì§€ì‹ì€ ë§ì§€ ì•Šì€ 40~60ëŒ€ ì¼ë°˜ í™˜ìì…ë‹ˆë‹¤.
ì´ í™˜ìëŠ” ìµœê·¼ ì‹¬í˜ˆê´€ ìœ„í—˜ í‰ê°€ë¥¼ ë°›ì•˜ìœ¼ë©°, ìì‹ ì˜ ìƒíƒœì— ë§ëŠ” ìƒí™œ ìŠµê´€ ê°œì„  ë°©ì•ˆì„ ì°¾ê³ ì í•©ë‹ˆë‹¤.

# ì…ë ¥ ì •ë³´ (Input)
ë‹¤ìŒì€ ì´ í™˜ìì˜ ì‹¬í˜ˆê´€ì§ˆí™˜ ê´€ë ¨ ì£¼ìš” ìœ„í—˜ ìš”ì¸ì…ë‹ˆë‹¤:
{risk_factors}

# ì‘ì—… ëª©í‘œ (Task)
ë‹¤ìŒ í•­ëª©ì„ í¬í•¨í•˜ì—¬, í™˜ì ë§ì¶¤í˜• ê±´ê°• ì²˜ë°©ì„ ì œê³µí•˜ì„¸ìš”:

1. **ê° ìœ„í—˜ ìš”ì¸ì´ ì‹¬í˜ˆê´€ì§ˆí™˜ ë°œë³‘ì— ì–´ë–¤ ì˜í–¥ì„ ì£¼ëŠ”ì§€ ì„¤ëª…**
   - ë‹¨ìˆœíˆ "ìœ„í—˜í•˜ë‹¤"ê°€ ì•„ë‹ˆë¼, ì™œ ê·¸ëŸ°ì§€ ë³‘íƒœìƒë¦¬ì ìœ¼ë¡œ 1~2ë¬¸ì¥ ë‚´ì™¸ë¡œ ì„¤ëª…
   - ê°€ëŠ¥í•œ ê²½ìš° ìˆ«ì (ì˜ˆ: í˜ˆì•• 140 ì´ìƒì´ë©´ ìœ„í—˜ì´ 2ë°° ì¦ê°€) í™œìš©

2. **ê° ìœ„í—˜ ìš”ì¸ì„ ì¤„ì´ê¸° ìœ„í•œ êµ¬ì²´ì ì¸ ì‹¤ì²œ ë°©ì•ˆ ì œì‹œ**
   - ë§¤ì¼ ê±·ê¸°, ì—¼ë¶„ ì¤„ì´ê¸° ë“± ì¼ìƒì—ì„œ ì‰½ê²Œ ì‹¤ì²œ ê°€ëŠ¥í•œ í–‰ë™ìœ¼ë¡œ
   - ê° í–‰ë™ì´ í•´ë‹¹ ìœ„í—˜ ìš”ì¸ì„ ì–´ë–»ê²Œ ê°œì„ í•˜ëŠ”ì§€ë„ ê°„ë‹¨íˆ ì„¤ëª…

3. **ê°œì¸í™”ëœ ì‹¤ì²œ íŒ ë˜ëŠ” ê²©ë ¤ ë©”ì‹œì§€ ì‚½ì…**
   - ì˜ˆ: "50ëŒ€ ì´í›„ì—ëŠ” í˜ˆì•• ê´€ë¦¬ê°€ íŠ¹íˆ ì¤‘ìš”í•©ë‹ˆë‹¤."
   - ëŒ€ìƒìì˜ ë‚˜ì´, ì„±ë³„, ìœ„í—˜ ì¡°í•© ë“±ì„ ê³ ë ¤í•œ ë§ì¶¤ ì½”ë©˜íŠ¸

4. **í•„ìš” ì‹œ ì˜ë£Œì  ì¡°ì¹˜ë‚˜ ì „ë¬¸ì˜ ìƒë‹´ ê¶Œê³  í¬í•¨**
   - íŠ¹ì • ìˆ˜ì¹˜(í˜ˆì••, í˜ˆë‹¹ ë“±)ê°€ ê¸°ì¤€ì¹˜ë¥¼ ë„˜ëŠ” ê²½ìš° ë³‘ì› ì§„ë£Œë¥¼ ê¶Œê³ 
   - ì•½ë¬¼ ì¹˜ë£Œ, í˜ˆì•¡ ê²€ì‚¬ ë“± ì‹¤ì œì  ì¡°ì¹˜ë„ ì–¸ê¸‰ ê°€ëŠ¥

5. **ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì°¸ê³  ìë£Œ 2~3ê°œ ì¶”ì²œ**
   - ìœ íŠœë¸Œ ì˜ìƒ: ì œëª©, ì„¤ëª…, ë§í¬
   - ê±´ê°• ì €ë„: ë…¼ë¬¸ ì œëª©, í•µì‹¬ ë‚´ìš©, ë§í¬
   - ê³µê³µê¸°ê´€ ê±´ê°• ì •ë³´ ì‚¬ì´íŠ¸ ë“±

6. **ìƒí™œìŠµê´€ ë³€í™” ìœ ì§€ë¥¼ ìœ„í•œ 'ì‘ì€ ì„±ê³µ ê²½í—˜' ì œì•ˆ**
   - í–‰ë™ì„ ìŠµê´€í™”í•˜ê¸° ìœ„í•œ êµ¬ì²´ì ì´ê³  ì¸¡ì • ê°€ëŠ¥í•œ ì˜ˆì‹œ í¬í•¨
   - ì˜ˆ: "ë§¤ì¼ ì•„ì¹¨ í˜ˆì•• ì¸¡ì •í•˜ê³  ê¸°ë¡í•˜ê¸°", "ì£¼ 3íšŒ ì¹œêµ¬ì™€ ê±·ê¸° ì±Œë¦°ì§€ ì°¸ì—¬"

# í˜•ì‹ ë° í†¤ (Format & Tone)
- ê° ìœ„í—˜ ìš”ì¸ì€ ë²ˆí˜¸ë‚˜ ì†Œì œëª©ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ëª…í™•í•˜ê²Œ êµ¬ì„±
- ì¤‘ìš”í•œ ì‹¤ì²œ í¬ì¸íŠ¸ëŠ” êµµì€ ê¸€ì”¨ë¡œ ê°•ì¡°
- ì„¤ëª…ì€ ì „ë¬¸ì„±ì„ ë‹´ë˜, ë°˜ë“œì‹œ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì“°ì„¸ìš”
- í•„ìš” ì‹œ ê°„ë‹¨í•œ ì˜ë£Œ ìš©ì–´ëŠ” ()ë‚˜ ì˜ˆì‹œë¡œ í’€ì–´ ì„¤ëª…
- ì „ì²´ ì–´ì¡°ëŠ” ì¹œì ˆí•˜ë©´ì„œë„ ì‹ ë¢°ê° ìˆëŠ” ì˜ë£Œ ì „ë¬¸ê°€ í†¤ ìœ ì§€
"""

    if BACKEND == "hf":
        # Hugging Face í˜¸ì¶œ
        try:
            resp = requests.post(
                HF_API_URL,
                headers={"Authorization": f"Bearer {HF_API_KEY}"},
                json={
                    "inputs": prompt,
                    "parameters": {
                        "max_new_tokens": 500,
                        "temperature": 0.7,
                        "repetition_penalty": 1.05,
                    },
                },
                timeout=120,
            )
            resp.raise_for_status()
            data = resp.json()
            if isinstance(data, list) and len(data) > 0 and "generated_text" in data[0]:
                return data[0]["generated_text"].strip()
            if isinstance(data, dict) and "error" in data:
                return f"âš ï¸ ëª¨ë¸ ì‘ë‹µ ëŒ€ê¸° ë˜ëŠ” ì˜¤ë¥˜: {data.get('error')}"
            return f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ: {data}"
        except Exception as e:
            return f"âŒ Hugging Face í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}"

    else:
        # OpenAI í˜¸ì¶œ
        try:
            client = OpenAI(api_key=OPENAI_API_KEY)
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì‹¬í˜ˆê´€ì§ˆí™˜ ì˜ˆë°© ë° ê´€ë¦¬ì— ì „ë¬¸ì„±ì„ ê°€ì§„ ì˜ì‚¬ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt},
                ],
                temperature=0.7,
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            return f"âŒ OpenAI í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}"

# ==============================
# ğŸ“Š ë°ëª¨ìš© LightGBM ëª¨ë¸
# ==============================
@st.cache_resource
def load_model():
    from sklearn.datasets import make_classification
    X, y = make_classification(n_samples=1000, n_features=11, random_state=42)
    lgb_train = lgb.Dataset(X, label=y)
    params = {"objective": "binary", "metric": "binary_logloss", "verbosity": -1}
    model = lgb.train(params, lgb_train, num_boost_round=10)
    return model

model = load_model()

# ==============================
# âš–ï¸ ì…ë ¥ê°’ ì „ì²˜ë¦¬ í•¨ìˆ˜
# ==============================
def classify_cholesterol(chol_value):
    if chol_value < 200: return 1
    elif 200 <= chol_value < 240: return 2
    else: return 3

def classify_gluc(gluc_value):
    if gluc_value < 100: return 1
    elif 100 <= gluc_value < 126: return 2
    else: return 3

# ==============================
# ğŸ–¥ï¸ Streamlit UI
# ==============================
st.set_page_config(page_title="ì‹¬í˜ˆê´€ì§ˆí™˜ ì˜ˆì¸¡ê¸°", layout="centered")
st.title("ğŸ©º ì‹¬í˜ˆê´€ì§ˆí™˜ 10ë…„ ìœ„í—˜ë„ ì˜ˆì¸¡ê¸°")

st.header("ğŸ“‹ ê±´ê°• ì •ë³´ ì…ë ¥")
age = st.slider("ë‚˜ì´", 20, 90, 50)
gender = st.radio("ì„±ë³„", ["ë‚¨ì„±", "ì—¬ì„±"])
ap_hi = st.number_input("ìˆ˜ì¶•ê¸° í˜ˆì••", value=120)
ap_lo = st.number_input("ì´ì™„ê¸° í˜ˆì••", value=80)
height_cm = st.number_input("í‚¤(cm)", value=170)
weight_kg = st.number_input("ëª¸ë¬´ê²Œ(kg)", value=65)
chol = st.number_input("ì½œë ˆìŠ¤í…Œë¡¤ ìˆ˜ì¹˜ (mg/dL)", min_value=100, max_value=400, value=180)
gluc = st.number_input("í˜ˆë‹¹ ìˆ˜ì¹˜ (ê³µë³µ mg/dL)", min_value=50, max_value=300, value=90)
smoke = st.checkbox("í¡ì—°")
alco = st.checkbox("ìŒì£¼")
active = st.checkbox("í™œë™ì  ìƒí™œ")

# ì…ë ¥ ì²˜ë¦¬
bmi = weight_kg / ((height_cm / 100) ** 2) if height_cm else 0
gender_num = 1 if gender == "ë‚¨ì„±" else 0
chol_cat = classify_cholesterol(chol)
gluc_cat = classify_gluc(gluc)
hypertension = int(ap_hi >= 140 or ap_lo >= 90)

user_input = {
    "age_years": age,
    "gender": gender_num,
    "ap_hi": ap_hi,
    "ap_lo": ap_lo,
    "bmi": bmi,
    "cholesterol": chol_cat,
    "gluc": gluc_cat,
    "smoke": int(smoke),
    "alco": int(alco),
    "active": int(active),
    "hypertension": hypertension,
}

# ì˜ˆì¸¡ í•¨ìˆ˜
def predict_risk(model, user_input: dict):
    features = ["age_years", "gender", "ap_hi", "ap_lo", "bmi",
                "cholesterol", "gluc", "smoke", "alco", "active", "hypertension"]
    df = pd.DataFrame([user_input])[features]
    return float(model.predict(df)[0])

# ë²„íŠ¼ ë™ì‘
if st.button("ğŸ” ìœ„í—˜ë„ ì˜ˆì¸¡"):
    risk = predict_risk(model, user_input)
    risk_percent = round(risk * 100, 2)
    st.subheader(f"ğŸ“ˆ ì˜ˆì¸¡ ê²°ê³¼: {risk_percent}%")

    risk_factors = {
        "ê³ í˜ˆì••": hypertension == 1,
        "í¡ì—°": smoke,
        "ìŒì£¼": alco,
        "ë¹„ë§Œ": bmi >= 25,
        "ê³ ì½œë ˆìŠ¤í…Œë¡¤": chol_cat >= 2,
        "ê³ í˜ˆë‹¹": gluc_cat >= 2,
        "ìš´ë™ ë¶€ì¡±": not active,
    }

    if risk_percent >= 15:
        st.warning("âš ï¸ ì‹¬í˜ˆê´€ê³„ ìœ„í—˜ì´ ë†’ì€ í¸ì…ë‹ˆë‹¤. ìƒí™œìŠµê´€ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        st.markdown("ğŸ’¡ **ë§ì¶¤í˜• ê±´ê°• ì²˜ë°© (ë°±ì—”ë“œ: {} ì‚¬ìš©)**".format(BACKEND.upper()))
        with st.spinner("ëª¨ë¸ì´ ê±´ê°• ì¡°ì–¸ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            advice = generate_lifestyle_advice(risk_factors)
            st.success("ìƒí™œ ì²˜ë°© ë„ì°© âœ…")
            st.markdown(advice)
    else:
        st.success("ğŸ‰ ì „ë°˜ì ìœ¼ë¡œ ìœ„í—˜ë„ê°€ ë‚®ìŠµë‹ˆë‹¤! ì§€ê¸ˆì²˜ëŸ¼ ê±´ê°•ì„ ì˜ ìœ ì§€í•˜ì„¸ìš”.")

st.markdown("---")
st.caption("ğŸ§  Powered by LightGBM + OpenAI/HuggingFace (Nemotron 49B) | Made with â¤ï¸ using Streamlit")
