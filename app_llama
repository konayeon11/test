# -*- coding: utf-8 -*-
# app_gpt.py

import streamlit as st
import pandas as pd
import lightgbm as lgb
import json
import requests
from openai import OpenAI

# ==============================
# ğŸ”‘ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
# ==============================
OPENAI_API_KEY = st.secrets.get("openai", {}).get("api_key")
HF_API_KEY = st.secrets.get("huggingface", {}).get("api_key")
HF_MODEL = st.secrets.get("huggingface", {}).get("model", "nvidia/Llama-3.3-Nemotron-Super-49B-v1.5")
HF_API_URL = st.secrets.get("huggingface", {}).get(
    "api_url", f"https://api-inference.huggingface.co/models/{HF_MODEL}"
)

# âœ… ë°±ì—”ë“œ ìë™ ì„ íƒ
BACKEND = "hf" if HF_API_KEY else ("openai" if OPENAI_API_KEY else None)
if BACKEND is None:
    st.error("âŒ ì‚¬ìš©í•  API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. secrets.tomlì— [huggingface.api_key] ë˜ëŠ” [openai.api_key]ë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”.")
    st.stop()

st.caption(f"âš™ï¸ í˜„ì¬ ë°±ì—”ë“œ: {BACKEND.upper()}")

# ==============================
# ğŸ§  ë§ì¶¤í˜• ì¡°ì–¸ ìƒì„± í•¨ìˆ˜
# ==============================
def generate_lifestyle_advice(risk_factors: dict) -> str:
    risk_factors_str = json.dumps(risk_factors, ensure_ascii=False)

    prompt = f"""
ë‹¹ì‹ ì€ ì‹¬í˜ˆê´€ì§ˆí™˜ ì˜ˆë°©ê³¼ ê´€ë¦¬ë¥¼ ì „ë¬¸ìœ¼ë¡œ í•˜ëŠ” ì˜ë£Œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
í™˜ìì˜ ìœ„í—˜ ìš”ì¸: {risk_factors_str}

ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•œ ë§ì¶¤í˜• ê±´ê°• ì²˜ë°©ì„ ì œê³µí•˜ì„¸ìš”:
1) ìœ„í—˜ ìš”ì¸ì˜ ì˜í–¥ (ìˆ«ìÂ·ë³‘íƒœìƒë¦¬ í¬í•¨, 1~2ë¬¸ì¥)
2) ìœ„í—˜ ìš”ì¸ë³„ ì‹¤ì²œ ë°©ì•ˆ (ì¼ìƒ í–‰ë™ + íš¨ê³¼ ì„¤ëª…)
3) ê°œì¸í™”ëœ ê²©ë ¤ ë©”ì‹œì§€
4) í•„ìš”ì‹œ ì˜ë£Œ ì¡°ì¹˜ ê¶Œê³ 
5) ì‹ ë¢° ê°€ëŠ¥í•œ ì°¸ê³ ìë£Œ 2~3ê°œ (ë§í¬ í¬í•¨)
6) ìŠµê´€í™”ë¥¼ ìœ„í•œ ì‘ì€ ì„±ê³µ ê²½í—˜ ì œì•ˆ
"""

    if BACKEND == "hf":
        # Hugging Face í˜¸ì¶œ
        try:
            resp = requests.post(
                HF_API_URL,
                headers={"Authorization": f"Bearer {HF_API_KEY}"},
                json={
                    "inputs": prompt,
                    "parameters": {
                        "max_new_tokens": 500,
                        "temperature": 0.7,
                        "repetition_penalty": 1.05,
                    },
                },
                timeout=120,
            )
            resp.raise_for_status()
            data = resp.json()
            if isinstance(data, list) and len(data) > 0 and "generated_text" in data[0]:
                return data[0]["generated_text"].strip()
            if isinstance(data, dict) and "error" in data:
                return f"âš ï¸ ëª¨ë¸ ì‘ë‹µ ëŒ€ê¸° ë˜ëŠ” ì˜¤ë¥˜: {data.get('error')}"
            return f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ: {data}"
        except Exception as e:
            return f"âŒ Hugging Face í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}"

    else:
        # OpenAI í˜¸ì¶œ
        try:
            client = OpenAI(api_key=OPENAI_API_KEY)
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì‹¬í˜ˆê´€ì§ˆí™˜ ì˜ˆë°© ë° ê´€ë¦¬ì— ì „ë¬¸ì„±ì„ ê°€ì§„ ì˜ì‚¬ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt},
                ],
                temperature=0.7,
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            return f"âŒ OpenAI í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}"

# ==============================
# ğŸ“Š ë°ëª¨ìš© LightGBM ëª¨ë¸
# ==============================
@st.cache_resource
def load_model():
    from sklearn.datasets import make_classification
    X, y = make_classification(n_samples=1000, n_features=11, random_state=42)
    lgb_train = lgb.Dataset(X, label=y)
    params = {"objective": "binary", "metric": "binary_logloss", "verbosity": -1}
    model = lgb.train(params, lgb_train, num_boost_round=10)
    return model

model = load_model()

# ==============================
# âš–ï¸ ì…ë ¥ê°’ ì „ì²˜ë¦¬ í•¨ìˆ˜
# ==============================
def classify_cholesterol(chol_value):
    if chol_value < 200: return 1
    elif 200 <= chol_value < 240: return 2
    else: return 3

def classify_gluc(gluc_value):
    if gluc_value < 100: return 1
    elif 100 <= gluc_value < 126: return 2
    else: return 3

# ==============================
# ğŸ–¥ï¸ Streamlit UI
# ==============================
st.set_page_config(page_title="ì‹¬í˜ˆê´€ì§ˆí™˜ ì˜ˆì¸¡ê¸°", layout="centered")
st.title("ğŸ©º ì‹¬í˜ˆê´€ì§ˆí™˜ 10ë…„ ìœ„í—˜ë„ ì˜ˆì¸¡ê¸°")

st.header("ğŸ“‹ ê±´ê°• ì •ë³´ ì…ë ¥")
age = st.slider("ë‚˜ì´", 20, 90, 50)
gender = st.radio("ì„±ë³„", ["ë‚¨ì„±", "ì—¬ì„±"])
ap_hi = st.number_input("ìˆ˜ì¶•ê¸° í˜ˆì••", value=120)
ap_lo = st.number_input("ì´ì™„ê¸° í˜ˆì••", value=80)
height_cm = st.number_input("í‚¤(cm)", value=170)
weight_kg = st.number_input("ëª¸ë¬´ê²Œ(kg)", value=65)
chol = st.number_input("ì½œë ˆìŠ¤í…Œë¡¤ ìˆ˜ì¹˜ (mg/dL)", min_value=100, max_value=400, value=180)
gluc = st.number_input("í˜ˆë‹¹ ìˆ˜ì¹˜ (ê³µë³µ mg/dL)", min_value=50, max_value=300, value=90)
smoke = st.checkbox("í¡ì—°")
alco = st.checkbox("ìŒì£¼")
active = st.checkbox("í™œë™ì  ìƒí™œ")

# ì…ë ¥ ì²˜ë¦¬
bmi = weight_kg / ((height_cm / 100) ** 2) if height_cm else 0
gender_num = 1 if gender == "ë‚¨ì„±" else 0
chol_cat = classify_cholesterol(chol)
gluc_cat = classify_gluc(gluc)
hypertension = int(ap_hi >= 140 or ap_lo >= 90)

user_input = {
    "age_years": age,
    "gender": gender_num,
    "ap_hi": ap_hi,
    "ap_lo": ap_lo,
    "bmi": bmi,
    "cholesterol": chol_cat,
    "gluc": gluc_cat,
    "smoke": int(smoke),
    "alco": int(alco),
    "active": int(active),
    "hypertension": hypertension,
}

# ì˜ˆì¸¡ í•¨ìˆ˜
def predict_risk(model, user_input: dict):
    features = ["age_years", "gender", "ap_hi", "ap_lo", "bmi",
                "cholesterol", "gluc", "smoke", "alco", "active", "hypertension"]
    df = pd.DataFrame([user_input])[features]
    return float(model.predict(df)[0])

# ë²„íŠ¼ ë™ì‘
if st.button("ğŸ” ìœ„í—˜ë„ ì˜ˆì¸¡"):
    risk = predict_risk(model, user_input)
    risk_percent = round(risk * 100, 2)
    st.subheader(f"ğŸ“ˆ ì˜ˆì¸¡ ê²°ê³¼: {risk_percent}%")

    risk_factors = {
        "ê³ í˜ˆì••": hypertension == 1,
        "í¡ì—°": smoke,
        "ìŒì£¼": alco,
        "ë¹„ë§Œ": bmi >= 25,
        "ê³ ì½œë ˆìŠ¤í…Œë¡¤": chol_cat >= 2,
        "ê³ í˜ˆë‹¹": gluc_cat >= 2,
        "ìš´ë™ ë¶€ì¡±": not active,
    }

    if risk_percent >= 15:
        st.warning("âš ï¸ ì‹¬í˜ˆê´€ê³„ ìœ„í—˜ì´ ë†’ì€ í¸ì…ë‹ˆë‹¤. ìƒí™œìŠµê´€ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        st.markdown("ğŸ’¡ **ë§ì¶¤í˜• ê±´ê°• ì²˜ë°© (ë°±ì—”ë“œ: {} ì‚¬ìš©)**".format(BACKEND.upper()))
        with st.spinner("ëª¨ë¸ì´ ê±´ê°• ì¡°ì–¸ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            advice = generate_lifestyle_advice(risk_factors)
            st.success("ìƒí™œ ì²˜ë°© ë„ì°© âœ…")
            st.markdown(advice)
    else:
        st.success("ğŸ‰ ì „ë°˜ì ìœ¼ë¡œ ìœ„í—˜ë„ê°€ ë‚®ìŠµë‹ˆë‹¤! ì§€ê¸ˆì²˜ëŸ¼ ê±´ê°•ì„ ì˜ ìœ ì§€í•˜ì„¸ìš”.")

st.markdown("---")
st.caption("ğŸ§  Powered by LightGBM + OpenAI/HuggingFace (Nemotron 49B) | Made with â¤ï¸ using Streamlit")
