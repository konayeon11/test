# -*- coding: utf-8 -*-
# app_gpt.py

import streamlit as st
import pandas as pd
import lightgbm as lgb
import os
import json
import requests

# ==============================
# âœ… Hugging Face Inference API ì„¤ì •
# ==============================
HF_API_KEY = st.secrets.get("huggingface", {}).get("api_key", "")
if not HF_API_KEY:
    st.error("âŒ Hugging Face API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. Streamlit Secretsì— 'huggingface.api_key'ë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”.")
    st.stop()

# Nemotron 49B (BF16) â€” Inference API ì—”ë“œí¬ì¸íŠ¸
HF_API_URL = "https://api-inference.huggingface.co/models/nvidia/Llama-3.3-Nemotron-Super-49B-v1.5"
HF_HEADERS = {"Authorization": f"Bearer {HF_API_KEY}"}

# ==============================
# âœ… Nemotron ê¸°ë°˜ ì¡°ì–¸ í•¨ìˆ˜ (Hugging Face ì‚¬ìš©)
# ==============================
def generate_lifestyle_advice(risk_factors: dict) -> str:
    """
    Hugging Face Inference APIë¥¼ í†µí•´ NVIDIA Llama-3.3-Nemotron-Super-49B-v1.5 ëª¨ë¸ë¡œ
    í•œêµ­ì–´ ê±´ê°• ì¡°ì–¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    risk_factors_str = json.dumps(risk_factors, ensure_ascii=False)

    # ë‹¨ì¼ í”„ë¡¬í”„íŠ¸(ì§€ì‹œ + ì…ë ¥). Chat í˜•ì‹ì´ ì•„ë‹ˆë¼ë„ ì¶©ë¶„íˆ ì˜ ë™ì‘í•˜ë„ë¡ êµ¬ì„±.
    prompt = f"""
ë‹¤ìŒ ì—­í• ê³¼ ì§€ì¹¨ì— ë”°ë¼ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.

[ì—­í• ]
- ë‹¹ì‹ ì€ ì‹¬í˜ˆê´€ì§ˆí™˜ ì˜ˆë°© ë° ê´€ë¦¬ì— ì „ë¬¸ì„±ì„ ê°€ì§„ ì„ìƒì˜ì…ë‹ˆë‹¤.

[ëŒ€ìƒ]
- 40~60ëŒ€ ì¼ë°˜ í™˜ìì´ë©°, ìµœê·¼ ì‹¬í˜ˆê´€ ìœ„í—˜ í‰ê°€ë¥¼ ë°›ì•˜ê³  ìƒí™œìŠµê´€ ì²˜ë°©ì„ ì›í•©ë‹ˆë‹¤.

[ì…ë ¥ ì •ë³´]
- í™˜ìì˜ ì£¼ìš” ìœ„í—˜ ìš”ì¸(JSON): {risk_factors_str}

[ì‘ì—… ëª©í‘œ]
1) ê° ìœ„í—˜ ìš”ì¸ì´ ì‹¬í˜ˆê´€ì§ˆí™˜ì— ë¯¸ì¹˜ëŠ” ì˜í–¥(ë³‘íƒœìƒë¦¬/ìˆ˜ì¹˜ í¬í•¨, 1~2ë¬¸ì¥)
2) ìœ„í—˜ ìš”ì¸ë³„ êµ¬ì²´ì  ì‹¤ì²œ ë°©ì•ˆ(ì¼ìƒ í–‰ë™ ì¤‘ì‹¬, íš¨ê³¼ ì„¤ëª… í¬í•¨)
3) ê°œì¸í™”ëœ ì‹¤ì²œ íŒ/ê²©ë ¤ ë©”ì‹œì§€(ë‚˜ì´/ìœ„í—˜ ì¡°í•© ê³ ë ¤)
4) ì§„ë£Œ/ê²€ì‚¬/ì•½ë¬¼ ë“± ì˜ë£Œì  ì¡°ì¹˜ ê¶Œê³ (ê¸°ì¤€ì¹˜ ì´ˆê³¼ ì‹œ)
5) ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì°¸ê³  ìë£Œ 2~3ê°œ(ì œëª©/ìš”ì•½/ë§í¬: ìœ íŠœë¸ŒÂ·í•™ìˆ Â·ê³µê³µê¸°ê´€ í˜¼í•©)
6) 'ì‘ì€ ì„±ê³µ ê²½í—˜' ì œì•ˆ(ì¸¡ì • ê°€ëŠ¥Â·êµ¬ì²´ì )

[í˜•ì‹]
- ë²ˆí˜¸/ì†Œì œëª©ìœ¼ë¡œ êµ¬ë¶„, í•µì‹¬ ì‹¤ì²œ í¬ì¸íŠ¸ëŠ” **êµµê²Œ**
- ì¹œì ˆí•˜ê³  ì‹ ë¢°ê° ìˆëŠ” ì˜ë£Œ ì „ë¬¸ê°€ í†¤
- ë¶ˆí•„ìš”í•œ ì„œë¡  ì—†ì´ ë°”ë¡œ ì²˜ë°©ë¶€í„° ì œì‹œ
- í•œêµ­ì–´ 100%

ì´ì œ ìœ„ í˜•ì‹ëŒ€ë¡œ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ì„¸ìš”.
""".strip()

    try:
        resp = requests.post(
            HF_API_URL,
            headers=HF_HEADERS,
            json={
                "inputs": prompt,
                "parameters": {
                    "max_new_tokens": 500,
                    "temperature": 0.7,
                    "repetition_penalty": 1.05,
                }
            },
            timeout=120
        )
        resp.raise_for_status()
        data = resp.json()

        # ì‘ë‹µ í˜•íƒœ ë°©ì–´ì  ì²˜ë¦¬
        # ë³´í†µ: [{'generated_text': '...'}]
        if isinstance(data, list) and len(data) > 0 and isinstance(data[0], dict):
            if "generated_text" in data[0]:
                return data[0]["generated_text"].strip()
            # ì¼ë¶€ ì—”ë“œí¬ì¸íŠ¸ëŠ” 'summary_text' ë“± ë‹¤ë¥¸ í‚¤ë¥¼ ì“°ê¸°ë„ í•¨
            for k in ("summary_text", "text", "response"):
                if k in data[0]:
                    return str(data[0][k]).strip()

        # dict ì—ëŸ¬(ëª¨ë¸ ë¡œë”©ì¤‘ ë“±) ë©”ì‹œì§€ ì²˜ë¦¬
        if isinstance(data, dict) and "error" in data:
            return f"âš ï¸ ëª¨ë¸ ì‘ë‹µ ëŒ€ê¸° ë˜ëŠ” ì˜¤ë¥˜: {data.get('error')}"

        return f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ í˜•ì‹: {data}"
    except Exception as e:
        return f"âŒ Hugging Face í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}"


# ==============================
# âœ… ë°ëª¨ìš© LightGBM ëª¨ë¸ (ìºì‹œ)
# ==============================
@st.cache_resource
def load_model():
    from sklearn.datasets import make_classification
    X, y = make_classification(n_samples=1000, n_features=11, random_state=42)
    lgb_train = lgb.Dataset(X, label=y)
    params = {"objective": "binary", "metric": "binary_logloss", "verbosity": -1}
    model = lgb.train(params, lgb_train, num_boost_round=10)
    return model

model = load_model()

# ==============================
# ğŸ”¢ ë³´ì¡° í•¨ìˆ˜: ë²”ì£¼í™”
# ==============================
def classify_cholesterol(chol_value):
    if chol_value < 200:
        return 1
    elif 200 <= chol_value < 240:
        return 2
    else:
        return 3

def classify_gluc(gluc_value):
    if gluc_value < 100:
        return 1
    elif 100 <= gluc_value < 126:
        return 2
    else:
        return 3

# ==============================
# ğŸ–¥ï¸ Streamlit UI
# ==============================
st.set_page_config(page_title="ì‹¬í˜ˆê´€ì§ˆí™˜ ì˜ˆì¸¡ê¸°", layout="centered")
st.title("ğŸ©º ì‹¬í˜ˆê´€ì§ˆí™˜ 10ë…„ ìœ„í—˜ë„ ì˜ˆì¸¡ê¸°")
st.markdown("ê±´ê°• ì •ë³´ë¥¼ ì…ë ¥í•˜ë©´ 10ë…„ ë‚´ ì‹¬í˜ˆê´€ì§ˆí™˜ ìœ„í—˜ì„ ì˜ˆì¸¡í•˜ê³ , í•„ìš” ì‹œ **Nemotron 49B ê¸°ë°˜** ë§ì¶¤í˜• ê±´ê°• ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤.")

st.header("ğŸ“‹ ê±´ê°• ì •ë³´ ì…ë ¥")
age = st.slider("ë‚˜ì´", 20, 90, 50)
gender = st.radio("ì„±ë³„", ["ë‚¨ì„±", "ì—¬ì„±"])
ap_hi = st.number_input("ìˆ˜ì¶•ê¸° í˜ˆì••", value=120)
ap_lo = st.number_input("ì´ì™„ê¸° í˜ˆì••", value=80)
height_cm = st.number_input("í‚¤(cm)", value=170)
weight_kg = st.number_input("ëª¸ë¬´ê²Œ(kg)", value=65)
chol = st.number_input("ì½œë ˆìŠ¤í…Œë¡¤ ìˆ˜ì¹˜ (mg/dL)", min_value=100, max_value=400, value=180)
gluc = st.number_input("í˜ˆë‹¹ ìˆ˜ì¹˜ (ê³µë³µ mg/dL)", min_value=50, max_value=300, value=90)
smoke = st.checkbox("í¡ì—°")
alco = st.checkbox("ìŒì£¼")
active = st.checkbox("í™œë™ì  ìƒí™œ")

# ì…ë ¥ ì²˜ë¦¬
bmi = weight_kg / ((height_cm / 100) ** 2) if height_cm else 0
gender_num = 1 if gender == "ë‚¨ì„±" else 0
chol_cat = classify_cholesterol(chol)
gluc_cat = classify_gluc(gluc)
hypertension = int(ap_hi >= 140 or ap_lo >= 90)

user_input = {
    "age_years": age,
    "gender": gender_num,
    "ap_hi": ap_hi,
    "ap_lo": ap_lo,
    "bmi": bmi,
    "cholesterol": chol_cat,
    "gluc": gluc_cat,
    "smoke": int(smoke),
    "alco": int(alco),
    "active": int(active),
    "hypertension": hypertension
}

# ì˜ˆì¸¡ í•¨ìˆ˜
def predict_risk(model, user_input: dict):
    features = ["age_years", "gender", "ap_hi", "ap_lo", "bmi",
                "cholesterol", "gluc", "smoke", "alco", "active", "hypertension"]
    df = pd.DataFrame([user_input])[features]
    return float(model.predict(df)[0])

# ë²„íŠ¼ ë™ì‘
if st.button("ğŸ” ìœ„í—˜ë„ ì˜ˆì¸¡"):
    risk = predict_risk(model, user_input)
    risk_percent = round(risk * 100, 2)
    st.subheader(f"ğŸ“ˆ ì˜ˆì¸¡ ê²°ê³¼: {risk_percent}%")

    risk_factors = {
        "ê³ í˜ˆì••": hypertension == 1,
        "í¡ì—°": smoke,
        "ìŒì£¼": alco,
        "ë¹„ë§Œ": bmi >= 25,
        "ê³ ì½œë ˆìŠ¤í…Œë¡¤": chol_cat >= 2,
        "ê³ í˜ˆë‹¹": gluc_cat >= 2,
        "ìš´ë™ ë¶€ì¡±": not active,
    }

    if risk_percent >= 15:
        st.warning("âš ï¸ ì‹¬í˜ˆê´€ê³„ ìœ„í—˜ì´ ë†’ì€ í¸ì…ë‹ˆë‹¤. ìƒí™œìŠµê´€ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        st.markdown("ğŸ’¡ **Nemotron 49B ê¸°ë°˜ ë§ì¶¤í˜• ê±´ê°• ì²˜ë°©**")
        with st.spinner("ëª¨ë¸ì´ ê±´ê°• ì¡°ì–¸ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            advice = generate_lifestyle_advice(risk_factors)
            st.success("ìƒí™œ ì²˜ë°© ë„ì°© âœ…")
            st.markdown(advice)
    else:
        st.success("ğŸ‰ ì „ë°˜ì ìœ¼ë¡œ ìœ„í—˜ë„ê°€ ë‚®ìŠµë‹ˆë‹¤! ì§€ê¸ˆì²˜ëŸ¼ ê±´ê°•ì„ ì˜ ìœ ì§€í•˜ì„¸ìš”.")

st.markdown("---")
st.caption("ğŸ§  Powered by LightGBM + NVIDIA Llama-3.3 Nemotron 49B | Made with â¤ï¸ using Streamlit")
